{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "This notebook contains (slightly theoretical) workflow for web services exposed by the EIDA (European Integrated Data Archive) Federation, focused on the EIDAWS-WFCatalog service and its functionalities allowing users to filter out low quality and low coverage data before downloading it to the local machine.\n",
    "\n",
    "In this example we are going to:\n",
    "\n",
    "1. Retrieve seismic event information from FDSNWS-Event catalogue offered by [GFZ](https://www.gfz-potsdam.de/) EIDA Node:\n",
    "    * Date:\n",
    "        * üìÖ start date = 2020-01-01\n",
    "        * üìÖ end date = 2020-06-01\n",
    "    * Event characteristics:\n",
    "        * üéöÔ∏è minimum magnitude = 5\n",
    "    * Coordinates:\n",
    "        * üåê minimum latitude = 40¬∞N\n",
    "        * üåê maximum latitude = 45¬∞N\n",
    "        * üåê minimum longitude = 17¬∞E\n",
    "        * üåê maximum longitude = 25¬∞E\n",
    "1. Using [FDSNWS-Station](https://www.orfeus-eu.org/data/eida/webservices/station/) web service, list all stations available in the same bounding box we used for our event search:\n",
    "    * üåê minimum latitude = 40¬∞N\n",
    "    * üåê maximum latitude = 45¬∞N\n",
    "    * üåê minimum longitude = 17¬∞E\n",
    "    * üåê maximum longitude = 25¬∞E\n",
    "1. Using [EIDAWS-WFCatalog](https://www.orfeus-eu.org/data/eida/webservices/wfcatalog/) service, we are going to exclude all stations which do not meet following criteria:\n",
    "    * At least 95% data coverage on the day of the event\n",
    "    * Maximum of 5 gaps\n",
    "    * Sum of gaps lower than 50 seconds\n",
    "    * No overlaps\n",
    "1. Using [FDSNWS-Dataselect](https://www.orfeus-eu.org/data/eida/webservices/dataselect/) web service, we are going to download miniSEED files containing the waveforms from a time window starting 5 minutes before and ending 15 minutes after, relative to the event origin time\n",
    "1. Using [FDSNWS-Station](https://www.orfeus-eu.org/data/eida/webservices/station/) web service, we are going to download StationXML file containing channel level station and instrumentation metadata\n",
    "1. At the end we are going to quickly demo the GUI-based tools based on the [EIDAWS-WFCatalog](https://www.orfeus-eu.org/data/eida/webservices/wfcatalog/) web service, available via [data quality page](https://www.orfeus-eu.org/data/eida/quality/) on the [orfeus-eu.org](https://orfeus-eu.org).\n",
    "\n",
    "# 1.1. Approach\n",
    "\n",
    "For downloading metadata (FDSNWS-Station), waveforms (FDSNWS-Dataselect) and metrics (EIDAWS-WFCatalog) we are going to use [EIDAWS-Federator](http://eida-federator.ethz.ch/) gateway. This means that data will be requested using:\n",
    "\n",
    "```python\n",
    "read_events(\n",
    "    pathname_or_url=None,\n",
    "    format=None,\n",
    "    **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "read(\n",
    "    pathname_or_url=None,\n",
    "    format=None,\n",
    "    headonly=False,\n",
    "    starttime=None,\n",
    "    endtime=None,\n",
    "    nearest_sample=True,\n",
    "    dtype=None,\n",
    "    apply_calib=False,\n",
    "    check_compression=True,\n",
    "    **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "rather than using the `RoutingClient` utilizing the [EIDAWS-Routing](https://www.orfeus-eu.org/data/eida/webservices/routing/):\n",
    "\n",
    "```python\n",
    "from obspy.clients.fdsn import RoutingClient\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "rsClient = RoutingClient(\"eida-routing\")\n",
    "st = rsClient.get_waveforms(\n",
    "    network=\"Z3\",\n",
    "    channel=\"HHZ\",\n",
    "    starttime=UTCDateTime(2016, 3, 1),\n",
    "    endtime=UTCDateTime(2016, 3, 1, 0, 2, 0)\n",
    ")\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è Please keep in mind that [EIDAWS-Federator](http://eida-federator.ethz.ch/) only provides acces to open data, so if your intention is to download restricted datasets, please refer to [EIDA/userfeedback](https://github.com/EIDA/userfeedback) GitHub repository for instructions.\n",
    "\n",
    "‚ö†Ô∏è ObsPy (as of v1.2.2) does not implement methods to work with EIDAWS-WFCatalog, this service needs to be called directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Finding event\n",
    "Lets start by finding an event. Below two completely different approaches have been presented:\n",
    "* Downloading event XML document directly from FDSNWS-Event web service\n",
    "* Downloading event information using ObsPy library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries required to process raw web service response\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the encoding and XML namespace\n",
    "ENCODING = \"utf-8\"\n",
    "NSMAP = {'mw': 'http://quakeml.org/xmlns/bed/1.2'}\n",
    "\n",
    "# Define start and end dates for event and station searches\n",
    "start = \"2020-01-01\"\n",
    "end = \"2020-06-01\"\n",
    "\n",
    "# Define event minimum magnitude\n",
    "min_mag = 5\n",
    "\n",
    "# Define the bounding box for event and station searches\n",
    "min_lat = 40\n",
    "max_lat = 45\n",
    "min_lon = 17\n",
    "max_lon = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build URL to retrieve event information from event catalogue hosted by GFZ\n",
    "events_url = (\n",
    "    f\"http://geofon.gfz-potsdam.de/fdsnws/event/1/query?\"\n",
    "    f\"start={start}&end={end}&\"\n",
    "    f\"minmag={min_mag}&\"\n",
    "    f\"minlat={min_lat}&minlon={min_lon}&\"\n",
    "    f\"maxlat={max_lat}&maxlon={max_lon}\"\n",
    ")\n",
    "\n",
    "# With our original parameters, following URL should be built:\n",
    "# http://geofon.gfz-potsdam.de/fdsnws/event/1/query?start=2020-01-01&end=2020-06-01&minmag=5&minlat=40&minlon=17&maxlat=45&maxlon=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire the request\n",
    "r = requests.get(events_url, timeout=10)\n",
    "r.encoding = ENCODING\n",
    "\n",
    "# Check the response\n",
    "if r.status_code == 200:\n",
    "    # Parse the XML response\n",
    "    event_root = ET.fromstring(r.text)\n",
    "    for event_element in event_root.findall(\"./mw:eventParameters/*\", namespaces=NSMAP):\n",
    "        # Get event ID from event_element attribute\n",
    "        event_id = event_element.get(\"publicID\")\n",
    "        \n",
    "        # Find event magnitude element\n",
    "        event_magnitude_element = event_element.find(\"./mw:magnitude/mw:mag/mw:value\", namespaces=NSMAP)\n",
    "        \n",
    "        # Get magnitude value from event_magnitude_element\n",
    "        event_magnitude = event_magnitude_element.text\n",
    "        \n",
    "        # Get event origin time element\n",
    "        event_origin_time_element = event_element.find(\"./mw:origin/mw:time/mw:value\", namespaces=NSMAP)\n",
    "        \n",
    "        # Get origin time value from event_origin_time_element\n",
    "        event_origin_time = event_origin_time_element.text\n",
    "        \n",
    "        print(f\"Event with ID: {event_id} happened on {event_origin_time} and had magnitude equal to: {event_magnitude}\")\n",
    "else:\n",
    "    print(\"Something went wrong...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with ObsPy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read_events\n",
    "\n",
    "# Read events using the same URL\n",
    "evts = read_events(events_url)\n",
    "\n",
    "# Print retrieved events\n",
    "for e in evts:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è Users are free to choose how they download data from EIDA, but for convenience we will continue using ObsPy throughout the rest of this notebook. ü¶•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Finding stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from obspy import read_inventory\n",
    "\n",
    "# Build URL using EIDA Federator and our defined parameters\n",
    "stations_url = (\n",
    "    f\"http://eida-federator.ethz.ch/fdsnws/station/1/query?\"\n",
    "    f\"start={start}&end={end}&\"\n",
    "    f\"minlat={min_lat}&minlon={min_lon}&\"\n",
    "    f\"maxlat={max_lat}&maxlon={max_lon}\"\n",
    ")\n",
    "\n",
    "inv = read_inventory(stations_url)\n",
    "\n",
    "print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to visualize our event and surrounding stations. Please notice that stations in this area are hosted by various EIDA nodes:\n",
    "- NOA\n",
    "- NIEP\n",
    "- GFZ\n",
    "- INGV\n",
    "- ODC\n",
    "\n",
    "![](img/eventAndStations.png)\n",
    "\n",
    "‚ö†Ô∏è This is a static image and will not change after adjusting the input parameters..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Filter stations which do not meet our quality criteria\n",
    "We want to download data from stations which have:\n",
    "1. At least 95% data availability on the day of the event\n",
    "1. Maximum of 5 gaps\n",
    "1. Sum of gaps lower than 50 seconds\n",
    "1. No overlaps\n",
    "\n",
    "First, lets see what default EIDAWS-WFCatalog response offers...\n",
    "\n",
    "http://eida-federator.ethz.ch/eidaws/wfcatalog/1/query?start=2020-01-28T20:10:10.670309&end=2020-01-28T20:30:10.670309&network=HL&station=KZN&channel=HHZ&include=all\n",
    "\n",
    "```json\n",
    "[{\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"producer\": {\n",
    "        \"name\": \"EIDA NODE\",\n",
    "        \"agent\": \"ObsPy mSEED-QC\",\n",
    "        \"created\": \"2020-01-29T08:39:49.718Z\"\n",
    "    },\n",
    "    \"station\": \"KZN\",\n",
    "    \"network\": \"HL\",\n",
    "    \"location\": \"\",\n",
    "    \"channel\": \"HHZ\",\n",
    "    \"num_gaps\": 3,\n",
    "    \"num_overlaps\": 0,\n",
    "    \"sum_gaps\": 5,\n",
    "    \"sum_overlaps\": 0,\n",
    "    \"max_gap\": 2,\n",
    "    \"max_overlap\": null,\n",
    "    \"record_length\": [512],\n",
    "    \"sample_rate\": [100],\n",
    "    \"percent_availability\": 99.99421296296296,\n",
    "    \"encoding\": [\"STEIM2\"],\n",
    "    \"num_records\": 16260,\n",
    "    \"start_time\": \"2020-01-28T00:00:00.000Z\",\n",
    "    \"end_time\": \"2020-01-29T00:00:00.000Z\",\n",
    "    \"format\": \"miniSEED\",\n",
    "    \"quality\": \"D\",\n",
    "    \"sample_min\": -21263,\n",
    "    \"sample_max\": 25253,\n",
    "    \"sample_mean\": 77.38187557150297,\n",
    "    \"sample_median\": 79,\n",
    "    \"sample_stdev\": 1157.057209432005,\n",
    "    \"sample_rms\": 1159.6419018669262,\n",
    "    \"sample_lower_quartile\": 37,\n",
    "    \"sample_upper_quartile\": 121,\n",
    "    \"miniseed_header_percentages\": {\n",
    "        \"timing_quality_mean\": 10,\n",
    "        \"timing_quality_median\": 10,\n",
    "        \"timing_quality_lower_quartile\": 10,\n",
    "        \"timing_quality_upper_quartile\": 10,\n",
    "        \"timing_quality_min\": 10,\n",
    "        \"timing_quality_max\": 10,\n",
    "        \"timing_correction\": 0,\n",
    "        \"io_and_clock_flags\": {\n",
    "            \"short_record_read\": 0,\n",
    "            \"station_volume\": 0,\n",
    "            \"start_time_series\": 0,\n",
    "            \"end_time_series\": 0,\n",
    "            \"clock_locked\": 0\n",
    "        },\n",
    "        \"data_quality_flags\": {\n",
    "            \"amplifier_saturation\": 0,\n",
    "            \"digitizer_clipping\": 0,\n",
    "            \"spikes\": 0,\n",
    "            \"glitches\": 0,\n",
    "            \"missing_padded_data\": 0,\n",
    "            \"telemetry_sync_error\": 0,\n",
    "            \"digital_filter_charging\": 0,\n",
    "            \"suspect_time_tag\": 0\n",
    "        },\n",
    "        \"activity_flags\": {\n",
    "            \"calibration_signal\": 0,\n",
    "            \"time_correction_applied\": 0,\n",
    "            \"event_begin\": 0,\n",
    "            \"event_end\": 0,\n",
    "            \"positive_leap\": 0,\n",
    "            \"negative_leap\": 0\n",
    "        }\n",
    "    }\n",
    "}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representation of origin time to datetime object\n",
    "dt_origin = datetime.strptime(event_origin_time, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "# Define relative time windows using event origin time\n",
    "dt_start = dt_origin - timedelta(minutes=5)\n",
    "dt_end = dt_origin + timedelta(minutes=15)\n",
    "\n",
    "# Get ISO8601 representation of our time window\n",
    "dt_start_iso = dt_start.isoformat()\n",
    "dt_end_iso = dt_end.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channels we are interested in\n",
    "# channels will be downloaded only if all specified components are present and validated\n",
    "required_channels = {\n",
    "    \"BH?\": [\"BHE\", \"BHN\", \"BHZ\"],\n",
    "    \"HH?\": [\"HHE\", \"HHN\", \"HHZ\"],\n",
    "    \"LH?\": [\"LHE\", \"LHN\", \"LHZ\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_station(string):\n",
    "    \"\"\"Our validating function which takes WFCatalog response json and returns\n",
    "    list of network/station/channels for which all components are\n",
    "    present and validated against our criteria.\n",
    "\n",
    "    Args:\n",
    "        string (string): JSON response from EIDAWS-WFCatalog web service\n",
    "\n",
    "    Returns:\n",
    "        []: List of validated networks, stations and channels\n",
    "        None: If no channels have been found, function returns `None`\n",
    "    \"\"\"\n",
    "    # Parse string to json object\n",
    "    j = json.loads(string)\n",
    "    \n",
    "    # Define channels_found as set to allow \n",
    "    channels_found = set()\n",
    "    channels_validated = []\n",
    "\n",
    "    for cha in j:\n",
    "        # Get network station channel identifiers\n",
    "        network_code = cha[\"network\"]\n",
    "        station_code = cha[\"station\"]\n",
    "        channel_code = cha[\"channel\"]\n",
    "        \n",
    "        # Get the quality metrics\n",
    "        availability = int(cha[\"percent_availability\"])\n",
    "        gaps = int(cha[\"num_gaps\"])\n",
    "        sum_gaps = int(cha[\"sum_gaps\"])\n",
    "        overlaps = int(cha[\"num_overlaps\"])\n",
    "        \n",
    "        msg = f\"{network_code}.{station_code}.{channel_code}: {availability}% coverage, {gaps} gaps ({sum_gaps}s), {overlaps} overlaps.\"\n",
    "        if availability < 95 or gaps > 5 or sum_gaps > 50 or overlaps > 0:\n",
    "            print(f\"NOK: {msg}\")\n",
    "        else:\n",
    "            print(f\"OK: {msg}\")\n",
    "            channels_found.add(channel_code.upper())\n",
    "\n",
    "    # If channel components are present and validated, add them to the channels_validated list\n",
    "    for c in required_channels.keys():\n",
    "        if all(e in channels_found for e in required_channels[c]):\n",
    "            channels_validated.append(c)\n",
    "\n",
    "    if len(channels_validated) > 0:\n",
    "        return \",\".join(channels_validated)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of verified stations, will be filled later\n",
    "validated_stations = []\n",
    "\n",
    "# Loop through all networks and stations found in the bounding box surrounding our event\n",
    "for net in inv:\n",
    "    for sta in net:\n",
    "        # Build WFCatalog URL (POST method is not avaiable via Federator)\n",
    "        wfcatalog_url = (\n",
    "            f\"http://eida-federator.ethz.ch/eidaws/wfcatalog/1/query?\"\n",
    "            f\"start={dt_start_iso}&end={dt_end_iso}&\"\n",
    "            f\"network={net.code}&station={sta.code}\"\n",
    "        )\n",
    "\n",
    "        # Request the data...\n",
    "        r = requests.get(wfcatalog_url, timeout=10)\n",
    "        r.encoding = ENCODING\n",
    "        \n",
    "        if r.status_code == 200:\n",
    "            # Validate station\n",
    "            cha = validate_station(r.text)\n",
    "            if cha:\n",
    "                # Validation passed, add to verified_stations list\n",
    "                validated_stations.append([net.code, sta.code, cha])\n",
    "        else:\n",
    "            # print(f\"No data for {net.code}.{sta.code}\")\n",
    "            pass\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pprint to improve readability\n",
    "import pprint\n",
    "\n",
    "# Let's print our validated stations\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(validated_stations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Download data for verified stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "\n",
    "# Loop through our validated stations, build URL, retrieve and read the data\n",
    "for s in validated_stations:\n",
    "    dataselect_url = (\n",
    "        f\"http://eida-federator.ethz.ch/fdsnws/dataselect/1/query?\"\n",
    "        f\"start={dt_start_iso}&end={dt_end_iso}&\"\n",
    "        f\"network={s[0]}&station={s[1]}&\"\n",
    "        f\"channel={s[2]}\"\n",
    "    )\n",
    "    \n",
    "    # Print URL used to retrieve given dataset\n",
    "    print(dataselect_url)\n",
    "    \n",
    "    # Request and load the data\n",
    "    st = read(dataselect_url)\n",
    "    \n",
    "    # Print waveform metadata and plot the waveforms\n",
    "    print(st)\n",
    "    st.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Download metadata for verified stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read_inventory\n",
    "\n",
    "# Loop through our validated stations, build URL, retrieve and read the metadata\n",
    "for s in validated_stations:\n",
    "    station_url = (\n",
    "        f\"http://eida-federator.ethz.ch/fdsnws/station/1/query?\"\n",
    "        f\"level=channel&\"\n",
    "        f\"start={dt_start_iso}&end={dt_end_iso}&\"\n",
    "        f\"network={s[0]}&station={s[1]}&\"\n",
    "        f\"channel={s[2]}\"\n",
    "    )\n",
    "    \n",
    "    # Print URL used to retrieve the metadata\n",
    "    print(station_url)\n",
    "    \n",
    "    # Request and load the metadata\n",
    "    inv = read_inventory(station_url)\n",
    "    \n",
    "    # Print the metadata\n",
    "    print(inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Quality tools on the orfeus-eu.org\n",
    "Overview of the EIDA Quality Tools: https://www.orfeus-eu.org/data/eida/quality/\n",
    "\n",
    "## 7.1. Availability\n",
    "Availability information can be easily previewed using web tool accessible via https://www.orfeus-eu.org/data/eida/quality/availability/:\n",
    "![](img/availability.png)\n",
    "\n",
    "## 7.2. Data Quality Inspector\n",
    "Data quality inspector rendering advanced waveform metrics is avaiable via https://www.orfeus-eu.org/data/eida/quality/metrics/.\n",
    "\n",
    "Following statistical parameters can be selected and rendered:\n",
    "* Quadratic mean\n",
    "* Standard deviation\n",
    "* Minimum\n",
    "* Maximum\n",
    "* Availability\n",
    "* Gaps\n",
    "* Sum of gaps\n",
    "* Overlaps\n",
    "* Sum of overlaps\n",
    "* Median\n",
    "* Mean\n",
    "* Lower quartile\n",
    "* Upper quartile\n",
    "\n",
    "![](img/inspector.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
